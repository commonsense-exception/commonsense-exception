{"distilroberta-base": {"accuracy_train": 0.7846607669616519, "accuracy_test_heldout_exception": 0.5213414634146342, "accuracy_test_all_generics": 0.27315914489311166, "accuracy_one_test_both_generic_exception": 0.26285714285714284, "accuracy_two_test_both_generic_exception": 0.5213414634146342, "checkpoint": 190000}, "albert-base-v2": {"accuracy_train": 0.761437908496732, "accuracy_test_heldout_exception": 0.46179401993355484, "accuracy_test_all_generics": 0.3226229508196721, "accuracy_one_test_both_generic_exception": 0.30194805194805197, "accuracy_two_test_both_generic_exception": 0.46179401993355484, "checkpoint": 270000}, "google/mobilebert-uncased": {"accuracy_train": 0.8391655450874832, "accuracy_test_heldout_exception": 0.5648648648648649, "accuracy_test_all_generics": 0.2543103448275862, "accuracy_one_test_both_generic_exception": 0.26666666666666666, "accuracy_two_test_both_generic_exception": 0.5648648648648649, "checkpoint": 210000}, "bert-base-cased": {"accuracy_train": 0.7704590818363274, "accuracy_test_heldout_exception": 0.5353260869565217, "accuracy_test_all_generics": 0.29663281667557456, "accuracy_one_test_both_generic_exception": 0.29333333333333333, "accuracy_two_test_both_generic_exception": 0.5353260869565217, "checkpoint": 190000}}